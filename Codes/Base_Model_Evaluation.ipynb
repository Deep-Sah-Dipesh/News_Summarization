{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f37b07be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade transformers datasets pandas evaluate rouge_score sentencepiece bert-score accelerate\n",
    "\n",
    "# Install BLEURT directly from its GitHub repository\n",
    "!pip install -q git+https://github.com/google-research/bleurt.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e625919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import evaluate\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, MT5ForConditionalGeneration\n",
    "\n",
    "# --- Configuration ---\n",
    "MODEL_PATH = \"mt5-base-cnn-summarizer-en-hi_v3/final_model\"\n",
    "FULL_DATA_PATH = \"../Dataset/final_cleaned_dataset_CNN.csv\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "PREFIX_ENG = \"summarize English: \"\n",
    "PREFIX_HIN = \"summarize Hindi: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7958e8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "c:\\Users\\admin\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and moving to cuda...\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "print(f\"Loading model and moving to {DEVICE}...\")\n",
    "\n",
    "model = MT5ForConditionalGeneration.from_pretrained(MODEL_PATH).to(DEVICE)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a3a576",
   "metadata": {},
   "source": [
    "Quantitative Evaluation - Trial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49701b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading full dataset from: ../Dataset/final_cleaned_dataset_CNN.csv\n",
      "Processing and splitting the dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa54bbdf20d74750a5c5036e2fe301ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recreated test set with 100 samples for evaluation.\n"
     ]
    }
   ],
   "source": [
    "# Load the full original dataset\n",
    "print(f\"Loading full dataset from: {FULL_DATA_PATH}\")\n",
    "df = pd.read_csv(FULL_DATA_PATH, engine=\"python\", on_bad_lines=\"skip\")\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "raw_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "\n",
    "# Define the same formatting function used in training\n",
    "def format_dataset(batch):\n",
    "    inputs, targets = [], []\n",
    "    for article, eng_summary, hin_summary in zip(\n",
    "        batch[\"raw_news_article\"], batch[\"english_summary\"], batch[\"hindi_summary\"]\n",
    "    ):\n",
    "        if isinstance(article, str):\n",
    "            inputs.append(PREFIX_ENG + article)\n",
    "            targets.append(eng_summary)\n",
    "            inputs.append(PREFIX_HIN + article)\n",
    "            targets.append(hin_summary)\n",
    "    return {\"inputs\": inputs, \"targets\": targets}\n",
    "\n",
    "\n",
    "# Process and split the dataset\n",
    "print(\"Processing and splitting the dataset...\")\n",
    "processed_dataset = raw_dataset.map(\n",
    "    format_dataset, batched=True, remove_columns=raw_dataset.column_names\n",
    ").flatten()\n",
    "\n",
    "# IMPORTANT: Use the same test_size and seed to get the identical test set\n",
    "train_test_split = processed_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "test_dataset = train_test_split[\"test\"]\n",
    "\n",
    "# For a quick test, let's use a smaller sample. Remove .select() for the full evaluation.\n",
    "test_sample = test_dataset.select(range(100))\n",
    "\n",
    "print(f\"Recreated test set with {len(test_sample)} samples for evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4692ccbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation metrics...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbb9e33a83547b6ac9d3cda3ecd6b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default BLEURT-Base checkpoint for sequence maximum length 128. You can use a bigger model for better results with e.g.: evaluate.load('bleurt', 'bleurt-large-512').\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63c14456dc84c69b02251faf2db4925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/405M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\admin\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\bleurt\\score.py:160: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Reading checkpoint C:\\Users\\admin\\.cache\\huggingface\\metrics\\bleurt\\default\\downloads\\extracted\\64a145a740562dda9fae1ce4fb71155ccaf922d41c2355bee049709b8590e973\\bleurt-base-128.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint bert_custom\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:bert_custom\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:128\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "WARNING:tensorflow:From c:\\Users\\admin\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\bleurt\\lib\\bert_tokenization.py:94: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76afd796dbff42ebb59eedce027187c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating summaries for the test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a77158b3c94c0c8dabd1abb80416c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Computing English Metrics ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432691f9197f4aa7a705af270bbaf4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\admin\\.cache\\huggingface\\hub\\models--roberta-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "addfbfbd9ba5492b8cd0424af1cf05ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1510914aa33246e895d717f04d44d32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6552fa054042de8f1d1023c4b1fffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32336834469142dba3b9ae40b7b29f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec660a71430457e932bdaf02b74fbe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ROUGE-2: 17.94\n",
      "  BLEURT Score: -0.3045\n",
      "  BERTScore Precision: 0.8991\n",
      "\n",
      "--- Computing Hindi Metrics ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc7b63362264f2181a2ed0d524c08a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\envs\\summarizer_env\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\admin\\.cache\\huggingface\\hub\\models--bert-base-multilingual-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57925167b8e94bd790f6bc3fbf954b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ea16033dc045d1957bc1a906901329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18a5e3ee18949b38c7ca2eeccb29388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679a6ac70a484909b4bf38d76cebebca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ROUGE-2: 18.13\n",
      "  BLEURT Score: -0.2792\n",
      "  BERTScore Precision: 0.7319\n"
     ]
    }
   ],
   "source": [
    "# Load metrics\n",
    "print(\"Loading evaluation metrics...\")\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "bleurt_metric = evaluate.load(\"bleurt\", module_type=\"metric\", checkpoint=\"BLEURT-20\")\n",
    "bertscore_metric = evaluate.load(\"bertscore\")\n",
    "\n",
    "# Generate predictions\n",
    "predictions = []\n",
    "references = []\n",
    "print(\"Generating summaries for the test set...\")\n",
    "\n",
    "for example in tqdm(test_sample):\n",
    "    inputs = tokenizer(\n",
    "        example[\"inputs\"], return_tensors=\"pt\", max_length=1024, truncation=True\n",
    "    ).to(DEVICE)\n",
    "    summary_ids = model.generate(\n",
    "        inputs.input_ids, max_length=256, num_beams=4, early_stopping=True\n",
    "    )\n",
    "    prediction = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    predictions.append(prediction)\n",
    "    references.append(example[\"targets\"])\n",
    "\n",
    "# Separate by language (even indices are English, odd are Hindi)\n",
    "eng_preds = predictions[::2]\n",
    "hin_preds = predictions[1::2]\n",
    "eng_refs = references[::2]\n",
    "hin_refs = references[1::2]\n",
    "\n",
    "# Compute and display results\n",
    "print(\"\\n--- Computing English Metrics ---\")\n",
    "rouge_eng = rouge_metric.compute(predictions=eng_preds, references=eng_refs)\n",
    "bleurt_eng = bleurt_metric.compute(predictions=eng_preds, references=eng_refs)\n",
    "bert_eng = bertscore_metric.compute(\n",
    "    predictions=eng_preds, references=eng_refs, lang=\"en\"\n",
    ")\n",
    "\n",
    "print(f\"  ROUGE-2: {rouge_eng['rouge2'] * 100:.2f}\")\n",
    "print(f\"  BLEURT Score: {sum(bleurt_eng['scores']) / len(bleurt_eng['scores']):.4f}\")\n",
    "print(\n",
    "    f\"  BERTScore Precision: {sum(bert_eng['precision']) / len(bert_eng['precision']):.4f}\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n--- Computing Hindi Metrics ---\")\n",
    "rouge_hin = rouge_metric.compute(predictions=hin_preds, references=hin_refs)\n",
    "bleurt_hin = bleurt_metric.compute(predictions=hin_preds, references=hin_refs)\n",
    "bert_hin = bertscore_metric.compute(\n",
    "    predictions=hin_preds, references=hin_refs, lang=\"hi\"\n",
    ")\n",
    "\n",
    "print(f\"  ROUGE-2: {rouge_hin['rouge2'] * 100:.2f}\")\n",
    "print(f\"  BLEURT Score: {sum(bleurt_hin['scores']) / len(bleurt_hin['scores']):.4f}\")\n",
    "print(\n",
    "    f\"  BERTScore Precision: {sum(bert_hin['precision']) / len(bert_hin['precision']):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14509c36",
   "metadata": {},
   "source": [
    "Quantitative Evaluation - Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b73a65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading full dataset from: ../Dataset/final_cleaned_dataset_CNN.csv\n",
      "Processing and splitting the dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c22513b0ac848acac3a582268d2c04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recreated test set with 100 samples for evaluation.\n"
     ]
    }
   ],
   "source": [
    "# Load the full original dataset\n",
    "print(f\"Loading full dataset from: {FULL_DATA_PATH}\")\n",
    "df = pd.read_csv(FULL_DATA_PATH, engine=\"python\", on_bad_lines=\"skip\")\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "raw_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "\n",
    "# Define the same formatting function used in training\n",
    "def format_dataset(batch):\n",
    "    inputs, targets = [], []\n",
    "    for article, eng_summary, hin_summary in zip(\n",
    "        batch[\"raw_news_article\"], batch[\"english_summary\"], batch[\"hindi_summary\"]\n",
    "    ):\n",
    "        if isinstance(article, str):\n",
    "            inputs.append(PREFIX_ENG + article)\n",
    "            targets.append(eng_summary)\n",
    "            inputs.append(PREFIX_HIN + article)\n",
    "            targets.append(hin_summary)\n",
    "    return {\"inputs\": inputs, \"targets\": targets}\n",
    "\n",
    "\n",
    "# Process and split the dataset\n",
    "print(\"Processing and splitting the dataset...\")\n",
    "processed_dataset = raw_dataset.map(\n",
    "    format_dataset, batched=True, remove_columns=raw_dataset.column_names\n",
    ").flatten()\n",
    "\n",
    "# IMPORTANT: Use the same test_size and seed to get the identical test set\n",
    "train_test_split = processed_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "test_dataset = train_test_split[\"test\"]\n",
    "\n",
    "# For a quick test, let's use a smaller sample. Remove .select() for the full evaluation.\n",
    "test_sample = test_dataset.select(range(100))\n",
    "\n",
    "print(f\"Recreated test set with {len(test_sample)} samples for evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8349c514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:evaluate_modules.metrics.evaluate-metric--bleurt.98e148b2f8c4a88aba5037e4e0e90c9fd9ec35dc37a054ded8cfef0fa801ffab.bleurt:Using default BLEURT-Base checkpoint for sequence maximum length 128. You can use a bigger model for better results with e.g.: evaluate.load('bleurt', 'bleurt-large-512').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint C:\\Users\\admin\\.cache\\huggingface\\metrics\\bleurt\\default\\downloads\\extracted\\64a145a740562dda9fae1ce4fb71155ccaf922d41c2355bee049709b8590e973\\bleurt-base-128.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint C:\\Users\\admin\\.cache\\huggingface\\metrics\\bleurt\\default\\downloads\\extracted\\64a145a740562dda9fae1ce4fb71155ccaf922d41c2355bee049709b8590e973\\bleurt-base-128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Config file found, reading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Config file found, reading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load checkpoint bert_custom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load checkpoint bert_custom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... name:bert_custom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... name:bert_custom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... vocab_file:vocab.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... vocab_file:vocab.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... do_lower_case:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... do_lower_case:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... max_seq_length:128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... max_seq_length:128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating WordPiece tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating WordPiece tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating summaries for the test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74acfe960ab34074bb2ca63b663ce209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Computing English Metrics ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ROUGE-2: 17.94\n",
      "  BLEURT Score: -0.3045\n",
      "  BERTScore Precision: 0.8991\n",
      "\n",
      "--- Computing Hindi Metrics ---\n",
      "  ROUGE-2: 18.13\n",
      "  BLEURT Score: -0.2792\n",
      "  BERTScore Precision: 0.7319\n"
     ]
    }
   ],
   "source": [
    "# Load metrics\n",
    "print(\"Loading evaluation metrics...\")\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "bleurt_metric = evaluate.load(\"bleurt\", module_type=\"metric\", checkpoint=\"BLEURT-20\")\n",
    "bertscore_metric = evaluate.load(\"bertscore\")\n",
    "\n",
    "# Generate predictions\n",
    "predictions = []\n",
    "references = []\n",
    "print(\"Generating summaries for the test set...\")\n",
    "\n",
    "for example in tqdm(test_sample):\n",
    "    inputs = tokenizer(\n",
    "        example[\"inputs\"], return_tensors=\"pt\", max_length=1024, truncation=True\n",
    "    ).to(DEVICE)\n",
    "    summary_ids = model.generate(\n",
    "        inputs.input_ids, max_length=256, num_beams=4, early_stopping=True\n",
    "    )\n",
    "    prediction = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    predictions.append(prediction)\n",
    "    references.append(example[\"targets\"])\n",
    "\n",
    "# Separate by language (even indices are English, odd are Hindi)\n",
    "eng_preds = predictions[::2]\n",
    "hin_preds = predictions[1::2]\n",
    "eng_refs = references[::2]\n",
    "hin_refs = references[1::2]\n",
    "\n",
    "# Compute and display results\n",
    "print(\"\\n--- Computing English Metrics ---\")\n",
    "rouge_eng = rouge_metric.compute(predictions=eng_preds, references=eng_refs)\n",
    "bleurt_eng = bleurt_metric.compute(predictions=eng_preds, references=eng_refs)\n",
    "bert_eng = bertscore_metric.compute(\n",
    "    predictions=eng_preds, references=eng_refs, lang=\"en\"\n",
    ")\n",
    "\n",
    "print(f\"  ROUGE-2: {rouge_eng['rouge2'] * 100:.2f}\")\n",
    "print(f\"  BLEURT Score: {sum(bleurt_eng['scores']) / len(bleurt_eng['scores']):.4f}\")\n",
    "print(\n",
    "    f\"  BERTScore Precision: {sum(bert_eng['precision']) / len(bert_eng['precision']):.4f}\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n--- Computing Hindi Metrics ---\")\n",
    "rouge_hin = rouge_metric.compute(predictions=hin_preds, references=hin_refs)\n",
    "bleurt_hin = bleurt_metric.compute(predictions=hin_preds, references=hin_refs)\n",
    "bert_hin = bertscore_metric.compute(\n",
    "    predictions=hin_preds, references=hin_refs, lang=\"hi\"\n",
    ")\n",
    "\n",
    "print(f\"  ROUGE-2: {rouge_hin['rouge2'] * 100:.2f}\")\n",
    "print(f\"  BLEURT Score: {sum(bleurt_hin['scores']) / len(bleurt_hin['scores']):.4f}\")\n",
    "print(\n",
    "    f\"  BERTScore Precision: {sum(bert_hin['precision']) / len(bert_hin['precision']):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3358751",
   "metadata": {},
   "source": [
    "Interactive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "423264b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_article(article_text):\n",
    "    \"\"\"\n",
    "    Generates and prints English and Hindi summaries for a given article text.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"               SOURCE ARTICLE\")\n",
    "    print(\"=\" * 50)\n",
    "    print(article_text)\n",
    "\n",
    "    # --- Generate English Summary ---\n",
    "    english_input = PREFIX_ENG + article_text\n",
    "    eng_inputs = tokenizer(\n",
    "        english_input, return_tensors=\"pt\", max_length=1024, truncation=True\n",
    "    ).to(DEVICE)\n",
    "    eng_summary_ids = model.generate(\n",
    "        eng_inputs.input_ids, max_length=150, num_beams=5, early_stopping=True\n",
    "    )\n",
    "    english_summary = tokenizer.decode(eng_summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"               ENGLISH SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    print(english_summary)\n",
    "\n",
    "    # --- Generate Hindi Summary ---\n",
    "    hindi_input = PREFIX_HIN + article_text\n",
    "    hin_inputs = tokenizer(\n",
    "        hindi_input, return_tensors=\"pt\", max_length=1024, truncation=True\n",
    "    ).to(DEVICE)\n",
    "    hin_summary_ids = model.generate(\n",
    "        hin_inputs.input_ids, max_length=200, num_beams=5, early_stopping=True\n",
    "    )\n",
    "    hindi_summary = tokenizer.decode(hin_summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"                 HINDI SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    print(hindi_summary)\n",
    "    print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a673f0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "               SOURCE ARTICLE\n",
      "==================================================\n",
      "\n",
      "India's Chandrayaan-3 mission has successfully soft-landed on the lunar surface, making it the fourth country to achieve this feat. The Vikram lander touched down near the Moon's south pole, an unexplored region believed to contain water ice. The successful landing is a historic moment for India's space program, demonstrating advanced capabilities in landing technology. The Pragyan rover will now descend from the lander to explore the lunar terrain and conduct scientific experiments for one lunar day, which is equivalent to 14 Earth days. The mission aims to study the Moon's geology and the potential for a sustained human presence.\n",
      "\n",
      "\n",
      "==================================================\n",
      "               ENGLISH SUMMARY\n",
      "==================================================\n",
      "Maharashtra's Chandrayaan-3 mission has successfully soft-landed on the lunar surface, making it the fourth country to achieve this feat. The Vikram lander touched down near the Moon's south pole, an unexplored region believed to contain water ice. The mission aims to study the Moon's geology and the potential for sustained human presence. The mission aims to study the Moon's geology and the potential for sustained human presence. The mission aims to study the Moon's geology and potential human presence. The mission aims to study the Moon's geology and the potential for sustained human presence.\n",
      "\n",
      "==================================================\n",
      "                 HINDI SUMMARY\n",
      "==================================================\n",
      "इंडिया के चंद्रयान-3 मिशन ने चंद्रयान-3 मिशन के माध्यम से लौटने का प्रयास किया है, जिससे यह भारत के चौथे राष्ट्र बन गया है। यह लौटने के लिए भारत के चौथे राष्ट्र बन गया है, जिससे यह चंद्रयान-3 मिशन चौथे राष्ट्र बन गया है। यह लौटने के लिए एक महत्वपूर्ण क्षण है, जो चंद्रयान-3 मिशन के लिए एक महत्वपूर्ण क्षण है। यह मिशन एक लौटने वाले दिन के रूप में एक लौटने वाले दिन के रूप में एक लौटने वाले दिन के रूप में एक लौटने वाले दिन के रूप में एक लौटने वाले दिन के रूप में एक लौटने वा\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Paste any news article here to test the model\n",
    "article_to_test = \"\"\"\n",
    "India's Chandrayaan-3 mission has successfully soft-landed on the lunar surface, making it the fourth country to achieve this feat. The Vikram lander touched down near the Moon's south pole, an unexplored region believed to contain water ice. The successful landing is a historic moment for India's space program, demonstrating advanced capabilities in landing technology. The Pragyan rover will now descend from the lander to explore the lunar terrain and conduct scientific experiments for one lunar day, which is equivalent to 14 Earth days. The mission aims to study the Moon's geology and the potential for a sustained human presence.\n",
    "\"\"\"\n",
    "\n",
    "summarize_article(article_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bebc5783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_high_quality_summary(article_text):\n",
    "    \"\"\"\n",
    "    Takes a news article string and prints high-quality English and Hindi summaries.\n",
    "    \"\"\"\n",
    "    PREFIX_ENG = \"summarize English: \"\n",
    "    PREFIX_HIN = \"summarize Hindi: \"\n",
    "\n",
    "    # --- Generation Hyperparameters ---\n",
    "    NUM_BEAMS = 8\n",
    "    LENGTH_PENALTY = 2.0\n",
    "    NO_REPEAT_NGRAM_SIZE = 3\n",
    "    MIN_SUMMARY_LENGTH = 50\n",
    "    MAX_SUMMARY_LENGTH = 256\n",
    "    \n",
    "    # --- Print Source Article ---\n",
    "    print(\"=\"*80)\n",
    "    print(\"SOURCE ARTICLE:\")\n",
    "    print(\"=\"*80)\n",
    "    print(article_text)\n",
    "\n",
    "    # --- Generate English Summary ---\n",
    "    eng_input_text = PREFIX_ENG + article_text\n",
    "    eng_inputs = tokenizer(eng_input_text, return_tensors=\"pt\", max_length=1024, truncation=True).to(DEVICE)\n",
    "    \n",
    "    # eng_summary_ids = model.generate(\n",
    "    #     eng_inputs.input_ids,\n",
    "    #     num_beams=NUM_BEAMS,\n",
    "    #     max_length=MAX_SUMMARY_LENGTH,\n",
    "    #     min_length=MIN_SUMMARY_LENGTH,\n",
    "    #     length_penalty=LENGTH_PENALTY,\n",
    "    #     no_repeat_ngram_size=NO_REPEAT_NGRAM_SIZE,\n",
    "    #     early_stopping=True\n",
    "    # )\n",
    "    # english_summary = tokenizer.decode(eng_summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # print(\"\\n\" + \"=\"*80)\n",
    "    # print(\"GENERATED ENGLISH SUMMARY:\")\n",
    "    # print(\"=\"*80)\n",
    "    # print(english_summary)\n",
    "\n",
    "    # --- Generate Hindi Summary ---\n",
    "    hin_input_text = PREFIX_HIN + article_text\n",
    "    hin_inputs = tokenizer(hin_input_text, return_tensors=\"pt\", max_length=1024, truncation=True).to(DEVICE)\n",
    "\n",
    "    hin_summary_ids = model.generate(\n",
    "        hin_inputs.input_ids,\n",
    "        num_beams=NUM_BEAMS,\n",
    "        max_length=MAX_SUMMARY_LENGTH,\n",
    "        min_length=MIN_SUMMARY_LENGTH,\n",
    "        length_penalty=LENGTH_PENALTY,\n",
    "        no_repeat_ngram_size=NO_REPEAT_NGRAM_SIZE,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    hindi_summary = tokenizer.decode(hin_summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GENERATED HINDI SUMMARY:\")\n",
    "    print(\"=\"*80)\n",
    "    print(hindi_summary)\n",
    "    print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe699b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SOURCE ARTICLE:\n",
      "================================================================================\n",
      "\n",
      "India secured a decisive victory over Australia in the final match of the T20 series, winning by a margin of 35 runs in Bengaluru. Batting first, India posted a competitive total of 198 for 4, thanks to a powerful half-century from captain Suryakumar Yadav, who scored 78 off just 45 balls. In response, Australia's chase faltered early as they lost key wickets to India's fast bowlers.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "GENERATED HINDI SUMMARY:\n",
      "================================================================================\n",
      "इंडिया ने ऑस्ट्रेलिया के खिलाफ ट20 सीज़न के फाइनल मैच में एक महत्वपूर्ण जीत हासिल की, जिसमें भारत ने 35 रन की बढ़त बनाए रखी। यह जीत इंडिया के कप्तान सुंदरकुमार यदव के नेतृत्व में हुई, जिन्होंने 78 से 45 बॉक्सों में 78 रन बनाए। इस जीत के बावजूद, आस्ट्रेलिया ने पहले ही एक प्रभावशाली हाफ-स्ट्राइकर के साथ शानदार वापसी की। बाद में, भारत ने मुख्य विकेटों को गंवाने के लिए कई विकेट हासिल किए, जबकि अन्य विकेट उनके पास थे। इस हार के बाद, इंडिया का प्रदर्शन तेज़ हो गया, और इंडिया की आक्रामक बल्लेबाजी कमजोर हुई।\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "article_to_test = \"\"\"\n",
    "India secured a decisive victory over Australia in the final match of the T20 series, winning by a margin of 35 runs in Bengaluru. Batting first, India posted a competitive total of 198 for 4, thanks to a powerful half-century from captain Suryakumar Yadav, who scored 78 off just 45 balls. In response, Australia's chase faltered early as they lost key wickets to India's fast bowlers.\n",
    "\"\"\"\n",
    "\n",
    "generate_high_quality_summary(article_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7180ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SOURCE ARTICLE:\n",
      "================================================================================\n",
      "\n",
      "A landmark international treaty to combat plastic pollution has been agreed upon by delegates from over 170 countries at a United Nations Environment Assembly session held in Nairobi. Hailed as the most significant environmental pact since the Paris Agreement, the resolution establishes an Intergovernmental Negotiating Committee (INC) tasked with drafting a legally binding agreement by the end of 2026. The future treaty aims to address the full lifecycle of plastic, from its production and design to its disposal and recycling. The negotiations were complex, with debates centering on whether the treaty should focus solely on plastic waste management or include caps on virgin plastic production. Major plastic-producing nations and fossil fuel companies had advocated for a focus on recycling, while a coalition of environmental groups and many developing nations pushed for stricter controls on production itself. The final resolution provides a broad mandate for the INC to consider all options.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "GENERATED HINDI SUMMARY:\n",
      "================================================================================\n",
      "नयाकिया में यूनाइटेड नेशनल ऊर्जा एजेंस के लिए एक महत्वपूर्ण अंतर्राष्ट्रीय समझौता, जिसमें 170 देशों के delegates शामिल थे, ने रिहा कर लिया है। यह प्रस्ताव 2026 तक 2026 के अंत तक एक लंबे समय तक का सबसे बड़ा अंतरराष्ट्रीय सहयोग (INC) बनाए रखता है, जिसका उद्देश्य प्लास्टिक पर्यावरण की पूरी जीवनशैली को संबोधित करना है। इसके अतिरिक्त, यह संयुक्त राष्ट्र इंटरग्रामीय  Negotiating Committee (INC), जिन्होंने 2026 में एक न्यायिक रूप से स्वीकार करने का लक्ष्य रखा है, को संभावित हस्ताक्षर करने की योजना बना रहा है, और विभिन्न विकासशील देशों और विकसित देशों ने प्राकृतिक पेट्रोल उत्पादन पर ध्यान केंद्रित करने पर विचार कर रहे थे। मुख्य मुद्दों में व्यापक विवादों का सामना करना पड़ा।\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "article_to_test = \"\"\"\n",
    "A landmark international treaty to combat plastic pollution has been agreed upon by delegates from over 170 countries at a United Nations Environment Assembly session held in Nairobi. Hailed as the most significant environmental pact since the Paris Agreement, the resolution establishes an Intergovernmental Negotiating Committee (INC) tasked with drafting a legally binding agreement by the end of 2026. The future treaty aims to address the full lifecycle of plastic, from its production and design to its disposal and recycling. The negotiations were complex, with debates centering on whether the treaty should focus solely on plastic waste management or include caps on virgin plastic production. Major plastic-producing nations and fossil fuel companies had advocated for a focus on recycling, while a coalition of environmental groups and many developing nations pushed for stricter controls on production itself. The final resolution provides a broad mandate for the INC to consider all options.\n",
    "\"\"\"\n",
    "\n",
    "generate_high_quality_summary(article_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3eeda6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SOURCE ARTICLE:\n",
      "================================================================================\n",
      "\n",
      "India's Chandrayaan-3 mission has successfully soft-landed on the lunar surface, making it the fourth country to achieve this feat. The Vikram lander touched down near the Moon's south pole, an unexplored region believed to contain water ice. The successful landing is a historic moment for India's space program, demonstrating advanced capabilities in landing technology. The Pragyan rover will now descend from the lander to explore the lunar terrain and conduct scientific experiments for one lunar day, which is equivalent to 14 Earth days. The mission aims to study the Moon's geology and the potential for a sustained human presence.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "GENERATED HINDI SUMMARY:\n",
      "================================================================================\n",
      "इंडिया के चंद्रयान-3 मिशन ने लौटने की तैयारी की है, जिससे यह भारत के चौथे राष्ट्र बन गया है। यह मिशन एक शानदार क्षण है, जिसका उद्देश्य मौन के दक्षिण पोल के पास पानी की ऊर्जा का अध्ययन करना है। मिशन का लक्ष्य मानव समुदाय के लिए एक महत्वपूर्ण भूमिका निभाना है, जो एक lunar सप्ताह की तुलना में 14 ईर्घ दिनों के रूप में 14 अरब दिनों का अंतर है। इस मिशन के मुख्य मकसद मानव प्रवेश के भविष्य के बारे में अध्ययन किया जाना है और इसके लिए 14 आकाश दिवस का उपयोग किया जाएगा। इसके अतिरिक्त, यह यात्रा एक मौसम रात के अनुसार 14 अश्वेत दिनों की संख्या है।\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "article_to_test = \"\"\"\n",
    "India's Chandrayaan-3 mission has successfully soft-landed on the lunar surface, making it the fourth country to achieve this feat. The Vikram lander touched down near the Moon's south pole, an unexplored region believed to contain water ice. The successful landing is a historic moment for India's space program, demonstrating advanced capabilities in landing technology. The Pragyan rover will now descend from the lander to explore the lunar terrain and conduct scientific experiments for one lunar day, which is equivalent to 14 Earth days. The mission aims to study the Moon's geology and the potential for a sustained human presence.\n",
    "\"\"\"\n",
    "\n",
    "generate_high_quality_summary(article_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f07fda96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SOURCE ARTICLE:\n",
      "================================================================================\n",
      "\n",
      "The Indian Space Research Organisation (ISRO) has successfully completed a critical test for its ambitious Gaganyaan mission, which aims to send Indian astronauts to space. The test involved the final integrated validation of the crew module's parachute system at a facility in Chandigarh. The parachutes are essential for ensuring the safe return and landing of the crew module. Officials confirmed that the system performed flawlessly under simulated flight conditions. This milestone moves India one step closer to launching its first crewed spaceflight, which is currently scheduled for late 2025. The Gaganyaan programme is a top priority for the nation's space agency, marking its entry into human space exploration.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "GENERATED HINDI SUMMARY:\n",
      "================================================================================\n",
      "The Indian Space Research Organisation (ISRO) ने अपने नए गगनयान मिशन के लिए एक महत्वपूर्ण परीक्षण किया है, जिसका उद्देश्य इंडोनेशियाई एथलीटों को अंतरिक्ष में लौटने की तैयारी करना है। उन्होंने कैंडीज में एक प्रशिक्षण केंद्र में तैयार कर लिया था, जिसमें विशेषज्ञों ने पुष्टि की कि यह प्रणाली सफल रूप से पूरी तरह से काम कर रही थी। अधिकारियों ने स्वीकार किया कि इसकी सफलता के बावजूद, यह मिशन मानव समुद्र तक पहुंचने का लक्ष्य है। यह नया मिशन 2025 तक शुरू होने की उम्मीद है, जो मानव ऊर्जा अध्ययन में अपनी पहली लड़ाई की शुरुआत कर रहा है। इसके अतिरिक्त, भारत अपने पहले जून 2025 में अपना पहला जूनियर समुद्री फ्लाइट शुरू करने की संभावना पर प्रकाश डालता है।\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "article_to_test = \"\"\"\n",
    "The Indian Space Research Organisation (ISRO) has successfully completed a critical test for its ambitious Gaganyaan mission, which aims to send Indian astronauts to space. The test involved the final integrated validation of the crew module's parachute system at a facility in Chandigarh. The parachutes are essential for ensuring the safe return and landing of the crew module. Officials confirmed that the system performed flawlessly under simulated flight conditions. This milestone moves India one step closer to launching its first crewed spaceflight, which is currently scheduled for late 2025. The Gaganyaan programme is a top priority for the nation's space agency, marking its entry into human space exploration.\n",
    "\"\"\"\n",
    "\n",
    "generate_high_quality_summary(article_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "419df0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SOURCE ARTICLE:\n",
      "================================================================================\n",
      "\n",
      "Google has announced a significant upgrade to its core AI model, Gemini. The new version, named Gemini 1.5 Pro, is designed to handle a much larger amount of information at once. The company claims it can process up to 1 million tokens, which is equivalent to an entire feature-length movie or over 700,000 words of text. This massive context window allows the model to understand and reason about very large documents, codebases, or hours of video content without forgetting earlier details. The new model is initially being made available to developers and enterprise customers through Google's AI Studio and Vertex AI platforms. This development is seen as a major step in the competition against other leading AI models like OpenAI's GPT-4.\n",
      "\n",
      "================================================================================\n",
      "GENERATED HINDI SUMMARY:\n",
      "================================================================================\n",
      "मैनचेस्टर गूगल ने अपनी प्रमुख AI मशीन, Gemini 1.5 Pro, को एक महत्वपूर्ण वृद्धि की घोषणा की है। इस नए संस्करण, जिसमें 1 मिलियन tokens शामिल हैं, यह एक पूर्ण समूह-लंबी वीडियो या 700,000 शब्दों के वीडियो के रूप में कार्य कर सकता है। यह नया संस्करण एक लंबी संख्या में जानकारी प्रदान करता है, जिसका उद्देश्य यह है कि इसे एक पूरी फिल्माया गया वीडियो और 700,000 घंटे की वीडियो सामग्री के बारे में समझने के लिए उपलब्ध कराया जा सके। इसके अतिरिक्त, इसका उपयोग एआई स्टोर और Vertex AI प्लेटफॉर्म के माध्यम से जारी किया जा रहा है, जो मुख्य रूप से Google's AI Studio और Vertex AI platforms में किया गया है। उन्होंने GPT-4 के विपरीत, OpenAI GPT-4.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "article_to_test = \"\"\"\n",
    "Google has announced a significant upgrade to its core AI model, Gemini. The new version, named Gemini 1.5 Pro, is designed to handle a much larger amount of information at once. The company claims it can process up to 1 million tokens, which is equivalent to an entire feature-length movie or over 700,000 words of text. This massive context window allows the model to understand and reason about very large documents, codebases, or hours of video content without forgetting earlier details. The new model is initially being made available to developers and enterprise customers through Google's AI Studio and Vertex AI platforms. This development is seen as a major step in the competition against other leading AI models like OpenAI's GPT-4.\"\"\"\n",
    "\n",
    "generate_high_quality_summary(article_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5febf24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SOURCE ARTICLE:\n",
      "================================================================================\n",
      "TThe Reserve Bank of India (RBI) has announced that it will keep the repo rate unchanged at 6.5% for the eighth consecutive time. The decision was made by the Monetary Policy Committee (MPC) following its recent three-day meeting. RBI Governor Shaktikanta Das stated that the committee is focused on ensuring inflation aligns with the target of 4% while supporting economic growth. The central bank also retained its GDP growth forecast for the current fiscal year at 7.2%. The decision was widely expected by economists, who believe that a stable policy rate is necessary to manage potential food price inflation and global economic uncertainties before considering any rate cuts later in the year.\n",
      "\n",
      "================================================================================\n",
      "GENERATED HINDI SUMMARY:\n",
      "================================================================================\n",
      "इंडिया के रिजर्व बैंक ऑफ इंडिया (RBI) ने घोषणा की है कि वह अपनी रिपोर्ट रेट 6.5% से कम करेंगे। यह निर्णय MPC (MPC) के माध्यम से किया गया था, जिसका उद्देश्य अर्थव्यवस्था की वृद्धि को बढ़ावा देना है। बैंक ने अपनी GDP growth forecast पर 7.2% का लक्ष्य रखा है, जिससे उन्होंने अपनी जीडीपी की आगामी तिमाही में 7.2% की बढ़त बनाए रखने की आवश्यकता पर जोर दिया। RBI के गवर्नर सुचिंतता डास ने कहा कि यह नीति 4% के लक्ष्य को पूरा करने के लिए आवश्यक है और इसके बावजूद, यह उल्लेखनीय है कि एक स्थिर नीति दर का उपयोग करना पड़ रहा है, जो वर्तमान साल के GDP की आगे बढ़ने की संभावना के विपरीत है।\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "article_to_test = \"\"\"TThe Reserve Bank of India (RBI) has announced that it will keep the repo rate unchanged at 6.5% for the eighth consecutive time. The decision was made by the Monetary Policy Committee (MPC) following its recent three-day meeting. RBI Governor Shaktikanta Das stated that the committee is focused on ensuring inflation aligns with the target of 4% while supporting economic growth. The central bank also retained its GDP growth forecast for the current fiscal year at 7.2%. The decision was widely expected by economists, who believe that a stable policy rate is necessary to manage potential food price inflation and global economic uncertainties before considering any rate cuts later in the year.\"\"\"\n",
    "generate_high_quality_summary(article_to_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarizer_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
