{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 4683,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.032030749519538756,
      "grad_norm": 0.9092363119125366,
      "learning_rate": 1.979073243647235e-05,
      "loss": 0.5884,
      "step": 50
    },
    {
      "epoch": 0.06406149903907751,
      "grad_norm": 0.7853806614875793,
      "learning_rate": 1.9581464872944695e-05,
      "loss": 0.4718,
      "step": 100
    },
    {
      "epoch": 0.09609224855861627,
      "grad_norm": 0.9207470417022705,
      "learning_rate": 1.9367926542814436e-05,
      "loss": 0.4386,
      "step": 150
    },
    {
      "epoch": 0.12812299807815503,
      "grad_norm": 0.8684635758399963,
      "learning_rate": 1.9154388212684177e-05,
      "loss": 0.4514,
      "step": 200
    },
    {
      "epoch": 0.1601537475976938,
      "grad_norm": 0.7525097727775574,
      "learning_rate": 1.8945120649156524e-05,
      "loss": 0.4631,
      "step": 250
    },
    {
      "epoch": 0.19218449711723254,
      "grad_norm": 0.517998456954956,
      "learning_rate": 1.873585308562887e-05,
      "loss": 0.4291,
      "step": 300
    },
    {
      "epoch": 0.2242152466367713,
      "grad_norm": 0.9133366942405701,
      "learning_rate": 1.8522314755498615e-05,
      "loss": 0.4414,
      "step": 350
    },
    {
      "epoch": 0.25624599615631005,
      "grad_norm": 1.3979978561401367,
      "learning_rate": 1.8308776425368356e-05,
      "loss": 0.3637,
      "step": 400
    },
    {
      "epoch": 0.2882767456758488,
      "grad_norm": 0.9698198437690735,
      "learning_rate": 1.8095238095238097e-05,
      "loss": 0.3139,
      "step": 450
    },
    {
      "epoch": 0.3203074951953876,
      "grad_norm": 7.104884624481201,
      "learning_rate": 1.788169976510784e-05,
      "loss": 0.3651,
      "step": 500
    },
    {
      "epoch": 0.3523382447149263,
      "grad_norm": 1.0286885499954224,
      "learning_rate": 1.766816143497758e-05,
      "loss": 0.3019,
      "step": 550
    },
    {
      "epoch": 0.3843689942344651,
      "grad_norm": 0.7625325322151184,
      "learning_rate": 1.745462310484732e-05,
      "loss": 0.2997,
      "step": 600
    },
    {
      "epoch": 0.41639974375400385,
      "grad_norm": 0.9195382595062256,
      "learning_rate": 1.724108477471706e-05,
      "loss": 0.2873,
      "step": 650
    },
    {
      "epoch": 0.4484304932735426,
      "grad_norm": 0.7801726460456848,
      "learning_rate": 1.7027546444586803e-05,
      "loss": 0.2927,
      "step": 700
    },
    {
      "epoch": 0.48046124279308133,
      "grad_norm": 0.832208514213562,
      "learning_rate": 1.6814008114456547e-05,
      "loss": 0.3325,
      "step": 750
    },
    {
      "epoch": 0.5124919923126201,
      "grad_norm": 0.798984169960022,
      "learning_rate": 1.660046978432629e-05,
      "loss": 0.2946,
      "step": 800
    },
    {
      "epoch": 0.5445227418321589,
      "grad_norm": 0.8243231177330017,
      "learning_rate": 1.638693145419603e-05,
      "loss": 0.2835,
      "step": 850
    },
    {
      "epoch": 0.5765534913516976,
      "grad_norm": 1.715644359588623,
      "learning_rate": 1.617339312406577e-05,
      "loss": 0.3327,
      "step": 900
    },
    {
      "epoch": 0.6085842408712364,
      "grad_norm": 0.7472918629646301,
      "learning_rate": 1.595985479393551e-05,
      "loss": 0.3152,
      "step": 950
    },
    {
      "epoch": 0.6406149903907752,
      "grad_norm": 0.7108072638511658,
      "learning_rate": 1.5746316463805253e-05,
      "loss": 0.2916,
      "step": 1000
    },
    {
      "epoch": 0.672645739910314,
      "grad_norm": 1.383978247642517,
      "learning_rate": 1.5532778133674994e-05,
      "loss": 0.3168,
      "step": 1050
    },
    {
      "epoch": 0.7046764894298526,
      "grad_norm": 0.8914569616317749,
      "learning_rate": 1.5319239803544738e-05,
      "loss": 0.298,
      "step": 1100
    },
    {
      "epoch": 0.7367072389493914,
      "grad_norm": 1.342285394668579,
      "learning_rate": 1.5105701473414481e-05,
      "loss": 0.2883,
      "step": 1150
    },
    {
      "epoch": 0.7687379884689302,
      "grad_norm": 0.874302089214325,
      "learning_rate": 1.4892163143284222e-05,
      "loss": 0.2873,
      "step": 1200
    },
    {
      "epoch": 0.8007687379884689,
      "grad_norm": 0.9762008786201477,
      "learning_rate": 1.4678624813153963e-05,
      "loss": 0.2825,
      "step": 1250
    },
    {
      "epoch": 0.8327994875080077,
      "grad_norm": 0.8463621139526367,
      "learning_rate": 1.4465086483023704e-05,
      "loss": 0.2681,
      "step": 1300
    },
    {
      "epoch": 0.8648302370275465,
      "grad_norm": 0.8638054728507996,
      "learning_rate": 1.4251548152893447e-05,
      "loss": 0.2681,
      "step": 1350
    },
    {
      "epoch": 0.8968609865470852,
      "grad_norm": 0.7593613266944885,
      "learning_rate": 1.4038009822763188e-05,
      "loss": 0.2534,
      "step": 1400
    },
    {
      "epoch": 0.928891736066624,
      "grad_norm": 0.5074706673622131,
      "learning_rate": 1.3824471492632929e-05,
      "loss": 0.2624,
      "step": 1450
    },
    {
      "epoch": 0.9609224855861627,
      "grad_norm": 0.8971844911575317,
      "learning_rate": 1.361093316250267e-05,
      "loss": 0.2895,
      "step": 1500
    },
    {
      "epoch": 0.9929532351057014,
      "grad_norm": 1.046599268913269,
      "learning_rate": 1.3397394832372413e-05,
      "loss": 0.255,
      "step": 1550
    },
    {
      "epoch": 1.0,
      "eval_bleurt_f1": 0.5552,
      "eval_loss": 0.25663241744041443,
      "eval_rouge1": 0.5876,
      "eval_rouge2": 0.533,
      "eval_rougeL": 0.5813,
      "eval_runtime": 2506.3126,
      "eval_samples_per_second": 0.319,
      "eval_steps_per_second": 0.08,
      "step": 1561
    },
    {
      "epoch": 1.0249839846252402,
      "grad_norm": 0.755357027053833,
      "learning_rate": 1.3183856502242154e-05,
      "loss": 0.2287,
      "step": 1600
    },
    {
      "epoch": 1.057014734144779,
      "grad_norm": 1.0892456769943237,
      "learning_rate": 1.2970318172111895e-05,
      "loss": 0.2245,
      "step": 1650
    },
    {
      "epoch": 1.0890454836643177,
      "grad_norm": 0.920231819152832,
      "learning_rate": 1.2756779841981636e-05,
      "loss": 0.2318,
      "step": 1700
    },
    {
      "epoch": 1.1210762331838564,
      "grad_norm": 0.6339905261993408,
      "learning_rate": 1.2543241511851379e-05,
      "loss": 0.2306,
      "step": 1750
    },
    {
      "epoch": 1.1531069827033953,
      "grad_norm": 0.6184355020523071,
      "learning_rate": 1.232970318172112e-05,
      "loss": 0.2294,
      "step": 1800
    },
    {
      "epoch": 1.185137732222934,
      "grad_norm": 0.8666595816612244,
      "learning_rate": 1.2116164851590861e-05,
      "loss": 0.2345,
      "step": 1850
    },
    {
      "epoch": 1.2171684817424728,
      "grad_norm": 0.7074686288833618,
      "learning_rate": 1.1902626521460602e-05,
      "loss": 0.2186,
      "step": 1900
    },
    {
      "epoch": 1.2491992312620115,
      "grad_norm": 0.6522018909454346,
      "learning_rate": 1.1689088191330345e-05,
      "loss": 0.2429,
      "step": 1950
    },
    {
      "epoch": 1.2812299807815504,
      "grad_norm": 0.9670304656028748,
      "learning_rate": 1.1475549861200086e-05,
      "loss": 0.2392,
      "step": 2000
    },
    {
      "epoch": 1.313260730301089,
      "grad_norm": 0.5310565233230591,
      "learning_rate": 1.1262011531069827e-05,
      "loss": 0.216,
      "step": 2050
    },
    {
      "epoch": 1.3452914798206277,
      "grad_norm": 0.5007979273796082,
      "learning_rate": 1.1048473200939568e-05,
      "loss": 0.2167,
      "step": 2100
    },
    {
      "epoch": 1.3773222293401666,
      "grad_norm": 0.728309690952301,
      "learning_rate": 1.0834934870809311e-05,
      "loss": 0.2313,
      "step": 2150
    },
    {
      "epoch": 1.4093529788597055,
      "grad_norm": 0.7757068276405334,
      "learning_rate": 1.0621396540679052e-05,
      "loss": 0.2302,
      "step": 2200
    },
    {
      "epoch": 1.4413837283792441,
      "grad_norm": 0.9180157780647278,
      "learning_rate": 1.0407858210548793e-05,
      "loss": 0.2215,
      "step": 2250
    },
    {
      "epoch": 1.4734144778987828,
      "grad_norm": 0.7052559852600098,
      "learning_rate": 1.0194319880418534e-05,
      "loss": 0.2322,
      "step": 2300
    },
    {
      "epoch": 1.5054452274183214,
      "grad_norm": 1.2846823930740356,
      "learning_rate": 9.980781550288277e-06,
      "loss": 0.2304,
      "step": 2350
    },
    {
      "epoch": 1.5374759769378603,
      "grad_norm": 0.645041823387146,
      "learning_rate": 9.76724322015802e-06,
      "loss": 0.2503,
      "step": 2400
    },
    {
      "epoch": 1.5695067264573992,
      "grad_norm": 0.6886671185493469,
      "learning_rate": 9.553704890027761e-06,
      "loss": 0.2319,
      "step": 2450
    },
    {
      "epoch": 1.6015374759769379,
      "grad_norm": 1.0130914449691772,
      "learning_rate": 9.340166559897502e-06,
      "loss": 0.2101,
      "step": 2500
    },
    {
      "epoch": 1.6335682254964765,
      "grad_norm": 1.2386693954467773,
      "learning_rate": 9.126628229767243e-06,
      "loss": 0.2388,
      "step": 2550
    },
    {
      "epoch": 1.6655989750160154,
      "grad_norm": 0.5843703150749207,
      "learning_rate": 8.913089899636986e-06,
      "loss": 0.2211,
      "step": 2600
    },
    {
      "epoch": 1.6976297245355543,
      "grad_norm": 0.7594293355941772,
      "learning_rate": 8.699551569506727e-06,
      "loss": 0.236,
      "step": 2650
    },
    {
      "epoch": 1.729660474055093,
      "grad_norm": 0.7538934946060181,
      "learning_rate": 8.486013239376468e-06,
      "loss": 0.227,
      "step": 2700
    },
    {
      "epoch": 1.7616912235746316,
      "grad_norm": 1.0286916494369507,
      "learning_rate": 8.27247490924621e-06,
      "loss": 0.2478,
      "step": 2750
    },
    {
      "epoch": 1.7937219730941703,
      "grad_norm": 0.9066137075424194,
      "learning_rate": 8.058936579115952e-06,
      "loss": 0.2227,
      "step": 2800
    },
    {
      "epoch": 1.8257527226137091,
      "grad_norm": 0.6507116556167603,
      "learning_rate": 7.845398248985695e-06,
      "loss": 0.2215,
      "step": 2850
    },
    {
      "epoch": 1.857783472133248,
      "grad_norm": 0.8014577627182007,
      "learning_rate": 7.631859918855436e-06,
      "loss": 0.2042,
      "step": 2900
    },
    {
      "epoch": 1.8898142216527867,
      "grad_norm": 0.843156099319458,
      "learning_rate": 7.418321588725177e-06,
      "loss": 0.2361,
      "step": 2950
    },
    {
      "epoch": 1.9218449711723253,
      "grad_norm": 1.0438448190689087,
      "learning_rate": 7.204783258594919e-06,
      "loss": 0.2463,
      "step": 3000
    },
    {
      "epoch": 1.9538757206918642,
      "grad_norm": 0.6923218965530396,
      "learning_rate": 6.99124492846466e-06,
      "loss": 0.2206,
      "step": 3050
    },
    {
      "epoch": 1.985906470211403,
      "grad_norm": 0.8633062243461609,
      "learning_rate": 6.777706598334402e-06,
      "loss": 0.2265,
      "step": 3100
    },
    {
      "epoch": 2.0,
      "eval_bleurt_f1": 0.58,
      "eval_loss": 0.2461947649717331,
      "eval_rouge1": 0.5982,
      "eval_rouge2": 0.5498,
      "eval_rougeL": 0.5932,
      "eval_runtime": 1743.1373,
      "eval_samples_per_second": 0.459,
      "eval_steps_per_second": 0.115,
      "step": 3122
    },
    {
      "epoch": 2.0179372197309418,
      "grad_norm": 0.9536944031715393,
      "learning_rate": 6.564168268204143e-06,
      "loss": 0.2008,
      "step": 3150
    },
    {
      "epoch": 2.0499679692504804,
      "grad_norm": 0.7551999092102051,
      "learning_rate": 6.350629938073885e-06,
      "loss": 0.1968,
      "step": 3200
    },
    {
      "epoch": 2.081998718770019,
      "grad_norm": 0.7813777923583984,
      "learning_rate": 6.137091607943626e-06,
      "loss": 0.2013,
      "step": 3250
    },
    {
      "epoch": 2.114029468289558,
      "grad_norm": 1.1082559823989868,
      "learning_rate": 5.923553277813368e-06,
      "loss": 0.198,
      "step": 3300
    },
    {
      "epoch": 2.146060217809097,
      "grad_norm": 1.097791075706482,
      "learning_rate": 5.710014947683109e-06,
      "loss": 0.1995,
      "step": 3350
    },
    {
      "epoch": 2.1780909673286355,
      "grad_norm": 0.47037917375564575,
      "learning_rate": 5.496476617552852e-06,
      "loss": 0.194,
      "step": 3400
    },
    {
      "epoch": 2.210121716848174,
      "grad_norm": 0.8478936553001404,
      "learning_rate": 5.2829382874225936e-06,
      "loss": 0.1907,
      "step": 3450
    },
    {
      "epoch": 2.242152466367713,
      "grad_norm": 0.7098076939582825,
      "learning_rate": 5.069399957292335e-06,
      "loss": 0.1961,
      "step": 3500
    },
    {
      "epoch": 2.274183215887252,
      "grad_norm": 1.0023748874664307,
      "learning_rate": 4.8558616271620766e-06,
      "loss": 0.2144,
      "step": 3550
    },
    {
      "epoch": 2.3062139654067906,
      "grad_norm": 0.7710154056549072,
      "learning_rate": 4.642323297031818e-06,
      "loss": 0.1984,
      "step": 3600
    },
    {
      "epoch": 2.3382447149263292,
      "grad_norm": 1.0507951974868774,
      "learning_rate": 4.42878496690156e-06,
      "loss": 0.1861,
      "step": 3650
    },
    {
      "epoch": 2.370275464445868,
      "grad_norm": 1.2406694889068604,
      "learning_rate": 4.215246636771301e-06,
      "loss": 0.2041,
      "step": 3700
    },
    {
      "epoch": 2.4023062139654066,
      "grad_norm": 0.914915919303894,
      "learning_rate": 4.001708306641043e-06,
      "loss": 0.1866,
      "step": 3750
    },
    {
      "epoch": 2.4343369634849457,
      "grad_norm": 0.9912995100021362,
      "learning_rate": 3.7881699765107837e-06,
      "loss": 0.205,
      "step": 3800
    },
    {
      "epoch": 2.4663677130044843,
      "grad_norm": 0.8437449336051941,
      "learning_rate": 3.574631646380526e-06,
      "loss": 0.2107,
      "step": 3850
    },
    {
      "epoch": 2.498398462524023,
      "grad_norm": 0.9691380262374878,
      "learning_rate": 3.3610933162502675e-06,
      "loss": 0.1965,
      "step": 3900
    },
    {
      "epoch": 2.530429212043562,
      "grad_norm": 0.8199869394302368,
      "learning_rate": 3.147554986120009e-06,
      "loss": 0.195,
      "step": 3950
    },
    {
      "epoch": 2.5624599615631007,
      "grad_norm": 0.7407156825065613,
      "learning_rate": 2.9340166559897505e-06,
      "loss": 0.1808,
      "step": 4000
    },
    {
      "epoch": 2.5944907110826394,
      "grad_norm": 1.2621725797653198,
      "learning_rate": 2.720478325859492e-06,
      "loss": 0.1989,
      "step": 4050
    },
    {
      "epoch": 2.626521460602178,
      "grad_norm": 0.8814780116081238,
      "learning_rate": 2.5069399957292335e-06,
      "loss": 0.1928,
      "step": 4100
    },
    {
      "epoch": 2.6585522101217167,
      "grad_norm": 1.378174901008606,
      "learning_rate": 2.293401665598975e-06,
      "loss": 0.2077,
      "step": 4150
    },
    {
      "epoch": 2.6905829596412554,
      "grad_norm": 0.8134996891021729,
      "learning_rate": 2.0798633354687166e-06,
      "loss": 0.2062,
      "step": 4200
    },
    {
      "epoch": 2.7226137091607945,
      "grad_norm": 0.9260764718055725,
      "learning_rate": 1.8663250053384585e-06,
      "loss": 0.1999,
      "step": 4250
    },
    {
      "epoch": 2.754644458680333,
      "grad_norm": 0.7150135636329651,
      "learning_rate": 1.6527866752082e-06,
      "loss": 0.1838,
      "step": 4300
    },
    {
      "epoch": 2.786675208199872,
      "grad_norm": 0.8990972638130188,
      "learning_rate": 1.4392483450779415e-06,
      "loss": 0.2007,
      "step": 4350
    },
    {
      "epoch": 2.818705957719411,
      "grad_norm": 0.9493874907493591,
      "learning_rate": 1.2257100149476832e-06,
      "loss": 0.1978,
      "step": 4400
    },
    {
      "epoch": 2.8507367072389496,
      "grad_norm": 0.8683595657348633,
      "learning_rate": 1.012171684817425e-06,
      "loss": 0.1873,
      "step": 4450
    },
    {
      "epoch": 2.8827674567584882,
      "grad_norm": 0.7688126564025879,
      "learning_rate": 7.986333546871663e-07,
      "loss": 0.1919,
      "step": 4500
    },
    {
      "epoch": 2.914798206278027,
      "grad_norm": 1.088922142982483,
      "learning_rate": 5.85095024556908e-07,
      "loss": 0.2082,
      "step": 4550
    },
    {
      "epoch": 2.9468289557975655,
      "grad_norm": 0.5974169969558716,
      "learning_rate": 3.715566944266496e-07,
      "loss": 0.185,
      "step": 4600
    },
    {
      "epoch": 2.978859705317104,
      "grad_norm": 0.5193585753440857,
      "learning_rate": 1.580183642963912e-07,
      "loss": 0.1946,
      "step": 4650
    },
    {
      "epoch": 3.0,
      "eval_bleurt_f1": 0.6113,
      "eval_loss": 0.24766410887241364,
      "eval_rouge1": 0.6205,
      "eval_rouge2": 0.5762,
      "eval_rougeL": 0.6179,
      "eval_runtime": 1882.3717,
      "eval_samples_per_second": 0.425,
      "eval_steps_per_second": 0.106,
      "step": 4683
    }
  ],
  "logging_steps": 50,
  "max_steps": 4683,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.0501421231151514e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
