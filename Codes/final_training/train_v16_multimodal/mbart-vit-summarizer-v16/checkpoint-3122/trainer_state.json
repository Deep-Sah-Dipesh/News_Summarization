{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 3122,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.032030749519538756,
      "grad_norm": 0.9092363119125366,
      "learning_rate": 1.979073243647235e-05,
      "loss": 0.5884,
      "step": 50
    },
    {
      "epoch": 0.06406149903907751,
      "grad_norm": 0.7853806614875793,
      "learning_rate": 1.9581464872944695e-05,
      "loss": 0.4718,
      "step": 100
    },
    {
      "epoch": 0.09609224855861627,
      "grad_norm": 0.9207470417022705,
      "learning_rate": 1.9367926542814436e-05,
      "loss": 0.4386,
      "step": 150
    },
    {
      "epoch": 0.12812299807815503,
      "grad_norm": 0.8684635758399963,
      "learning_rate": 1.9154388212684177e-05,
      "loss": 0.4514,
      "step": 200
    },
    {
      "epoch": 0.1601537475976938,
      "grad_norm": 0.7525097727775574,
      "learning_rate": 1.8945120649156524e-05,
      "loss": 0.4631,
      "step": 250
    },
    {
      "epoch": 0.19218449711723254,
      "grad_norm": 0.517998456954956,
      "learning_rate": 1.873585308562887e-05,
      "loss": 0.4291,
      "step": 300
    },
    {
      "epoch": 0.2242152466367713,
      "grad_norm": 0.9133366942405701,
      "learning_rate": 1.8522314755498615e-05,
      "loss": 0.4414,
      "step": 350
    },
    {
      "epoch": 0.25624599615631005,
      "grad_norm": 1.3979978561401367,
      "learning_rate": 1.8308776425368356e-05,
      "loss": 0.3637,
      "step": 400
    },
    {
      "epoch": 0.2882767456758488,
      "grad_norm": 0.9698198437690735,
      "learning_rate": 1.8095238095238097e-05,
      "loss": 0.3139,
      "step": 450
    },
    {
      "epoch": 0.3203074951953876,
      "grad_norm": 7.104884624481201,
      "learning_rate": 1.788169976510784e-05,
      "loss": 0.3651,
      "step": 500
    },
    {
      "epoch": 0.3523382447149263,
      "grad_norm": 1.0286885499954224,
      "learning_rate": 1.766816143497758e-05,
      "loss": 0.3019,
      "step": 550
    },
    {
      "epoch": 0.3843689942344651,
      "grad_norm": 0.7625325322151184,
      "learning_rate": 1.745462310484732e-05,
      "loss": 0.2997,
      "step": 600
    },
    {
      "epoch": 0.41639974375400385,
      "grad_norm": 0.9195382595062256,
      "learning_rate": 1.724108477471706e-05,
      "loss": 0.2873,
      "step": 650
    },
    {
      "epoch": 0.4484304932735426,
      "grad_norm": 0.7801726460456848,
      "learning_rate": 1.7027546444586803e-05,
      "loss": 0.2927,
      "step": 700
    },
    {
      "epoch": 0.48046124279308133,
      "grad_norm": 0.832208514213562,
      "learning_rate": 1.6814008114456547e-05,
      "loss": 0.3325,
      "step": 750
    },
    {
      "epoch": 0.5124919923126201,
      "grad_norm": 0.798984169960022,
      "learning_rate": 1.660046978432629e-05,
      "loss": 0.2946,
      "step": 800
    },
    {
      "epoch": 0.5445227418321589,
      "grad_norm": 0.8243231177330017,
      "learning_rate": 1.638693145419603e-05,
      "loss": 0.2835,
      "step": 850
    },
    {
      "epoch": 0.5765534913516976,
      "grad_norm": 1.715644359588623,
      "learning_rate": 1.617339312406577e-05,
      "loss": 0.3327,
      "step": 900
    },
    {
      "epoch": 0.6085842408712364,
      "grad_norm": 0.7472918629646301,
      "learning_rate": 1.595985479393551e-05,
      "loss": 0.3152,
      "step": 950
    },
    {
      "epoch": 0.6406149903907752,
      "grad_norm": 0.7108072638511658,
      "learning_rate": 1.5746316463805253e-05,
      "loss": 0.2916,
      "step": 1000
    },
    {
      "epoch": 0.672645739910314,
      "grad_norm": 1.383978247642517,
      "learning_rate": 1.5532778133674994e-05,
      "loss": 0.3168,
      "step": 1050
    },
    {
      "epoch": 0.7046764894298526,
      "grad_norm": 0.8914569616317749,
      "learning_rate": 1.5319239803544738e-05,
      "loss": 0.298,
      "step": 1100
    },
    {
      "epoch": 0.7367072389493914,
      "grad_norm": 1.342285394668579,
      "learning_rate": 1.5105701473414481e-05,
      "loss": 0.2883,
      "step": 1150
    },
    {
      "epoch": 0.7687379884689302,
      "grad_norm": 0.874302089214325,
      "learning_rate": 1.4892163143284222e-05,
      "loss": 0.2873,
      "step": 1200
    },
    {
      "epoch": 0.8007687379884689,
      "grad_norm": 0.9762008786201477,
      "learning_rate": 1.4678624813153963e-05,
      "loss": 0.2825,
      "step": 1250
    },
    {
      "epoch": 0.8327994875080077,
      "grad_norm": 0.8463621139526367,
      "learning_rate": 1.4465086483023704e-05,
      "loss": 0.2681,
      "step": 1300
    },
    {
      "epoch": 0.8648302370275465,
      "grad_norm": 0.8638054728507996,
      "learning_rate": 1.4251548152893447e-05,
      "loss": 0.2681,
      "step": 1350
    },
    {
      "epoch": 0.8968609865470852,
      "grad_norm": 0.7593613266944885,
      "learning_rate": 1.4038009822763188e-05,
      "loss": 0.2534,
      "step": 1400
    },
    {
      "epoch": 0.928891736066624,
      "grad_norm": 0.5074706673622131,
      "learning_rate": 1.3824471492632929e-05,
      "loss": 0.2624,
      "step": 1450
    },
    {
      "epoch": 0.9609224855861627,
      "grad_norm": 0.8971844911575317,
      "learning_rate": 1.361093316250267e-05,
      "loss": 0.2895,
      "step": 1500
    },
    {
      "epoch": 0.9929532351057014,
      "grad_norm": 1.046599268913269,
      "learning_rate": 1.3397394832372413e-05,
      "loss": 0.255,
      "step": 1550
    },
    {
      "epoch": 1.0,
      "eval_bleurt_f1": 0.5552,
      "eval_loss": 0.25663241744041443,
      "eval_rouge1": 0.5876,
      "eval_rouge2": 0.533,
      "eval_rougeL": 0.5813,
      "eval_runtime": 2506.3126,
      "eval_samples_per_second": 0.319,
      "eval_steps_per_second": 0.08,
      "step": 1561
    },
    {
      "epoch": 1.0249839846252402,
      "grad_norm": 0.755357027053833,
      "learning_rate": 1.3183856502242154e-05,
      "loss": 0.2287,
      "step": 1600
    },
    {
      "epoch": 1.057014734144779,
      "grad_norm": 1.0892456769943237,
      "learning_rate": 1.2970318172111895e-05,
      "loss": 0.2245,
      "step": 1650
    },
    {
      "epoch": 1.0890454836643177,
      "grad_norm": 0.920231819152832,
      "learning_rate": 1.2756779841981636e-05,
      "loss": 0.2318,
      "step": 1700
    },
    {
      "epoch": 1.1210762331838564,
      "grad_norm": 0.6339905261993408,
      "learning_rate": 1.2543241511851379e-05,
      "loss": 0.2306,
      "step": 1750
    },
    {
      "epoch": 1.1531069827033953,
      "grad_norm": 0.6184355020523071,
      "learning_rate": 1.232970318172112e-05,
      "loss": 0.2294,
      "step": 1800
    },
    {
      "epoch": 1.185137732222934,
      "grad_norm": 0.8666595816612244,
      "learning_rate": 1.2116164851590861e-05,
      "loss": 0.2345,
      "step": 1850
    },
    {
      "epoch": 1.2171684817424728,
      "grad_norm": 0.7074686288833618,
      "learning_rate": 1.1902626521460602e-05,
      "loss": 0.2186,
      "step": 1900
    },
    {
      "epoch": 1.2491992312620115,
      "grad_norm": 0.6522018909454346,
      "learning_rate": 1.1689088191330345e-05,
      "loss": 0.2429,
      "step": 1950
    },
    {
      "epoch": 1.2812299807815504,
      "grad_norm": 0.9670304656028748,
      "learning_rate": 1.1475549861200086e-05,
      "loss": 0.2392,
      "step": 2000
    },
    {
      "epoch": 1.313260730301089,
      "grad_norm": 0.5310565233230591,
      "learning_rate": 1.1262011531069827e-05,
      "loss": 0.216,
      "step": 2050
    },
    {
      "epoch": 1.3452914798206277,
      "grad_norm": 0.5007979273796082,
      "learning_rate": 1.1048473200939568e-05,
      "loss": 0.2167,
      "step": 2100
    },
    {
      "epoch": 1.3773222293401666,
      "grad_norm": 0.728309690952301,
      "learning_rate": 1.0834934870809311e-05,
      "loss": 0.2313,
      "step": 2150
    },
    {
      "epoch": 1.4093529788597055,
      "grad_norm": 0.7757068276405334,
      "learning_rate": 1.0621396540679052e-05,
      "loss": 0.2302,
      "step": 2200
    },
    {
      "epoch": 1.4413837283792441,
      "grad_norm": 0.9180157780647278,
      "learning_rate": 1.0407858210548793e-05,
      "loss": 0.2215,
      "step": 2250
    },
    {
      "epoch": 1.4734144778987828,
      "grad_norm": 0.7052559852600098,
      "learning_rate": 1.0194319880418534e-05,
      "loss": 0.2322,
      "step": 2300
    },
    {
      "epoch": 1.5054452274183214,
      "grad_norm": 1.2846823930740356,
      "learning_rate": 9.980781550288277e-06,
      "loss": 0.2304,
      "step": 2350
    },
    {
      "epoch": 1.5374759769378603,
      "grad_norm": 0.645041823387146,
      "learning_rate": 9.76724322015802e-06,
      "loss": 0.2503,
      "step": 2400
    },
    {
      "epoch": 1.5695067264573992,
      "grad_norm": 0.6886671185493469,
      "learning_rate": 9.553704890027761e-06,
      "loss": 0.2319,
      "step": 2450
    },
    {
      "epoch": 1.6015374759769379,
      "grad_norm": 1.0130914449691772,
      "learning_rate": 9.340166559897502e-06,
      "loss": 0.2101,
      "step": 2500
    },
    {
      "epoch": 1.6335682254964765,
      "grad_norm": 1.2386693954467773,
      "learning_rate": 9.126628229767243e-06,
      "loss": 0.2388,
      "step": 2550
    },
    {
      "epoch": 1.6655989750160154,
      "grad_norm": 0.5843703150749207,
      "learning_rate": 8.913089899636986e-06,
      "loss": 0.2211,
      "step": 2600
    },
    {
      "epoch": 1.6976297245355543,
      "grad_norm": 0.7594293355941772,
      "learning_rate": 8.699551569506727e-06,
      "loss": 0.236,
      "step": 2650
    },
    {
      "epoch": 1.729660474055093,
      "grad_norm": 0.7538934946060181,
      "learning_rate": 8.486013239376468e-06,
      "loss": 0.227,
      "step": 2700
    },
    {
      "epoch": 1.7616912235746316,
      "grad_norm": 1.0286916494369507,
      "learning_rate": 8.27247490924621e-06,
      "loss": 0.2478,
      "step": 2750
    },
    {
      "epoch": 1.7937219730941703,
      "grad_norm": 0.9066137075424194,
      "learning_rate": 8.058936579115952e-06,
      "loss": 0.2227,
      "step": 2800
    },
    {
      "epoch": 1.8257527226137091,
      "grad_norm": 0.6507116556167603,
      "learning_rate": 7.845398248985695e-06,
      "loss": 0.2215,
      "step": 2850
    },
    {
      "epoch": 1.857783472133248,
      "grad_norm": 0.8014577627182007,
      "learning_rate": 7.631859918855436e-06,
      "loss": 0.2042,
      "step": 2900
    },
    {
      "epoch": 1.8898142216527867,
      "grad_norm": 0.843156099319458,
      "learning_rate": 7.418321588725177e-06,
      "loss": 0.2361,
      "step": 2950
    },
    {
      "epoch": 1.9218449711723253,
      "grad_norm": 1.0438448190689087,
      "learning_rate": 7.204783258594919e-06,
      "loss": 0.2463,
      "step": 3000
    },
    {
      "epoch": 1.9538757206918642,
      "grad_norm": 0.6923218965530396,
      "learning_rate": 6.99124492846466e-06,
      "loss": 0.2206,
      "step": 3050
    },
    {
      "epoch": 1.985906470211403,
      "grad_norm": 0.8633062243461609,
      "learning_rate": 6.777706598334402e-06,
      "loss": 0.2265,
      "step": 3100
    },
    {
      "epoch": 2.0,
      "eval_bleurt_f1": 0.58,
      "eval_loss": 0.2461947649717331,
      "eval_rouge1": 0.5982,
      "eval_rouge2": 0.5498,
      "eval_rougeL": 0.5932,
      "eval_runtime": 1743.1373,
      "eval_samples_per_second": 0.459,
      "eval_steps_per_second": 0.115,
      "step": 3122
    }
  ],
  "logging_steps": 50,
  "max_steps": 4683,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.7000947487434342e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
