{'loss': 17.3691, 'grad_norm': 24710.8671875, 'learning_rate': 1e-05, 'epoch': 0.05}
  2%|▏         | 150/6642 [04:29<2:45:05,  1.53s/it]{'loss': 15.1896, 'grad_norm': 1253.855712890625, 'learning_rate': 1.5e-05, 'epoch': 0.07}
  3%|▎         | 200/6642 [05:47<2:38:21,  1.47s/it]{'loss': 11.4705, 'grad_norm': 1275.7470703125, 'learning_rate': 2e-05, 'epoch': 0.09}
  4%|▍         | 250/6642 [06:58<2:38:23,  1.49s/it]{'loss': 7.257, 'grad_norm': 19.44481086730957, 'learning_rate': 2.5e-05, 'epoch': 0.11}
  5%|▍         | 300/6642 [07:58<2:12:24,  1.25s/it]{'loss': 4.3326, 'grad_norm': 11.529706954956055, 'learning_rate': 3e-05, 'epoch': 0.14}
  5%|▌         | 350/6642 [09:01<1:42:27,  1.02it/s]{'loss': 3.6727, 'grad_norm': 3.133930206298828, 'learning_rate': 3.5e-05, 'epoch': 0.16}
  6%|▌         | 400/6642 [10:18<2:50:58,  1.64s/it]{'loss': 3.3826, 'grad_norm': 3.2587127685546875, 'learning_rate': 4e-05, 'epoch': 0.18}
  7%|▋         | 450/6642 [11:22<2:01:21,  1.18s/it]{'loss': 3.4258, 'grad_norm': 2.94587779045105, 'learning_rate': 4.5e-05, 'epoch': 0.2}
  8%|▊         | 500/6642 [12:22<2:09:01,  1.26s/it]{'loss': 3.2653, 'grad_norm': 2.916131019592285, 'learning_rate': 5e-05, 'epoch': 0.23}
  8%|▊         | 550/6642 [13:28<1:49:31,  1.08s/it]{'loss': 3.1574, 'grad_norm': 2.276667833328247, 'learning_rate': 4.959296646043634e-05, 'epoch': 0.25}
  9%|▉         | 600/6642 [14:29<1:44:05,  1.03s/it]{'loss': 3.1425, 'grad_norm': 3.2969565391540527, 'learning_rate': 4.9185932920872686e-05, 'epoch': 0.27}
 10%|▉         | 650/6642 [15:53<2:37:25,  1.58s/it]{'loss': 3.0699, 'grad_norm': 2.586760997772217, 'learning_rate': 4.8778899381309024e-05, 'epoch': 0.29}
 11%|█         | 700/6642 [17:06<1:37:12,  1.02it/s]{'loss': 3.0012, 'grad_norm': 2.9604198932647705, 'learning_rate': 4.837186584174536e-05, 'epoch': 0.32}
 11%|█▏        | 750/6642 [17:56<1:43:36,  1.06s/it]{'loss': 2.9563, 'grad_norm': 2.398463487625122, 'learning_rate': 4.79648323021817e-05, 'epoch': 0.34}
 12%|█▏        | 800/6642 [18:55<2:05:23,  1.29s/it]{'loss': 2.9003, 'grad_norm': 2.998619794845581, 'learning_rate': 4.7557798762618045e-05, 'epoch': 0.36}
 13%|█▎        | 850/6642 [19:57<2:11:00,  1.36s/it]{'loss': 2.909, 'grad_norm': 2.534437894821167, 'learning_rate': 4.7150765223054384e-05, 'epoch': 0.38}
 14%|█▎        | 900/6642 [20:47<1:21:09,  1.18it/s]{'loss': 2.96, 'grad_norm': 2.140286445617676, 'learning_rate': 4.674373168349072e-05, 'epoch': 0.41}
 14%|█▍        | 950/6642 [21:40<1:24:51,  1.12it/s]{'loss': 2.8684, 'grad_norm': 2.402892589569092, 'learning_rate': 4.633669814392706e-05, 'epoch': 0.43}
 15%|█▌        | 1000/6642 [22:33<1:50:25,  1.17s/it]{'loss': 2.877, 'grad_norm': 2.3655755519866943, 'learning_rate': 4.5929664604363405e-05, 'epoch': 0.45}
 16%|█▌        | 1050/6642 [23:35<2:05:17,  1.34s/it]{'loss': 2.7866, 'grad_norm': 3.0120809078216553, 'learning_rate': 4.552263106479974e-05, 'epoch': 0.47}
 17%|█▋        | 1100/6642 [24:38<1:59:18,  1.29s/it]{'loss': 2.799, 'grad_norm': 2.3288731575012207, 'learning_rate': 4.511559752523608e-05, 'epoch': 0.5}
 17%|█▋        | 1150/6642 [25:45<1:56:08,  1.27s/it]{'loss': 2.761, 'grad_norm': 2.0763607025146484, 'learning_rate': 4.470856398567242e-05, 'epoch': 0.52}
 18%|█▊        | 1200/6642 [26:41<2:15:02,  1.49s/it]{'loss': 2.787, 'grad_norm': 2.4499988555908203, 'learning_rate': 4.4301530446108765e-05, 'epoch': 0.54}
 19%|█▉        | 1250/6642 [27:35<1:22:43,  1.09it/s]{'loss': 2.7463, 'grad_norm': 2.4600257873535156, 'learning_rate': 4.38944969065451e-05, 'epoch': 0.56}
 20%|█▉        | 1300/6642 [28:34<1:38:50,  1.11s/it]{'loss': 2.7063, 'grad_norm': 2.149730682373047, 'learning_rate': 4.348746336698144e-05, 'epoch': 0.59}
 20%|██        | 1350/6642 [29:34<1:45:07,  1.19s/it]{'loss': 2.7094, 'grad_norm': 2.884317636489868, 'learning_rate': 4.308042982741778e-05, 'epoch': 0.61}
 21%|██        | 1400/6642 [30:25<1:17:47,  1.12it/s]{'loss': 2.707, 'grad_norm': 2.2151288986206055, 'learning_rate': 4.2673396287854124e-05, 'epoch': 0.63}
 22%|██▏       | 1450/6642 [31:24<2:26:38,  1.69s/it]{'loss': 2.6963, 'grad_norm': 2.1696739196777344, 'learning_rate': 4.226636274829046e-05, 'epoch': 0.65}
 23%|██▎       | 1500/6642 [32:34<1:37:04,  1.13s/it]{'loss': 2.7001, 'grad_norm': 1.9839057922363281, 'learning_rate': 4.18593292087268e-05, 'epoch': 0.68}
 23%|██▎       | 1550/6642 [33:36<2:00:39,  1.42s/it]{'loss': 2.6753, 'grad_norm': 2.3683249950408936, 'learning_rate': 4.1452295669163146e-05, 'epoch': 0.7}
 24%|██▍       | 1600/6642 [34:48<1:34:02,  1.12s/it]{'loss': 2.6208, 'grad_norm': 2.190981388092041, 'learning_rate': 4.1045262129599484e-05, 'epoch': 0.72}
 25%|██▍       | 1650/6642 [35:41<1:39:47,  1.20s/it]{'loss': 2.6683, 'grad_norm': 2.2084054946899414, 'learning_rate': 4.063822859003582e-05, 'epoch': 0.75}
 26%|██▌       | 1700/6642 [37:04<2:15:07,  1.64s/it]{'loss': 2.6425, 'grad_norm': 2.8109753131866455, 'learning_rate': 4.023119505047216e-05, 'epoch': 0.77}
 26%|██▋       | 1750/6642 [38:15<2:01:18,  1.49s/it]{'loss': 2.6371, 'grad_norm': 2.0437192916870117, 'learning_rate': 3.9824161510908506e-05, 'epoch': 0.79}
 27%|██▋       | 1800/6642 [39:34<1:33:57,  1.16s/it]{'loss': 2.61, 'grad_norm': 2.209165096282959, 'learning_rate': 3.9417127971344844e-05, 'epoch': 0.81}
 28%|██▊       | 1850/6642 [40:32<1:41:25,  1.27s/it]{'loss': 2.6236, 'grad_norm': 2.6539177894592285, 'learning_rate': 3.901009443178118e-05, 'epoch': 0.84}
 29%|██▊       | 1900/6642 [41:26<1:58:56,  1.51s/it]{'loss': 2.5873, 'grad_norm': 2.196930408477783, 'learning_rate': 3.860306089221752e-05, 'epoch': 0.86}
 29%|██▉       | 1950/6642 [42:20<1:11:22,  1.10it/s]{'loss': 2.575, 'grad_norm': 2.296056032180786, 'learning_rate': 3.8196027352653865e-05, 'epoch': 0.88}
 30%|███       | 2000/6642 [43:22<1:29:03,  1.15s/it]{'loss': 2.5951, 'grad_norm': 2.392451524734497, 'learning_rate': 3.7788993813090204e-05, 'epoch': 0.9}
 31%|███       | 2050/6642 [44:13<1:01:55,  1.24it/s]{'loss': 2.5612, 'grad_norm': 2.19561505317688, 'learning_rate': 3.738196027352654e-05, 'epoch': 0.93}
 32%|███▏      | 2100/6642 [45:48<2:25:21,  1.92s/it]{'loss': 2.5424, 'grad_norm': 2.6735122203826904, 'learning_rate': 3.697492673396288e-05, 'epoch': 0.95}
 32%|███▏      | 2150/6642 [47:21<1:31:32,  1.22s/it]{'loss': 2.5664, 'grad_norm': 2.106947898864746, 'learning_rate': 3.6567893194399225e-05, 'epoch': 0.97}
 33%|███▎      | 2200/6642 [49:05<2:28:31,  2.01s/it]{'loss': 2.5255, 'grad_norm': 2.2351150512695312, 'learning_rate': 3.616085965483556e-05, 'epoch': 0.99}
 33%|███▎      | 2214/6642 [49:28<1:53:43,  1.54s/it]c:\Users\admin\anaconda3\envs\news_summarizer\lib\site-packages\transformers\generation\utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
                                                     
 33%|███▎      | 2214/6642 [53:05<1:53:43,  1.54s/it]{'eval_loss': 1.9671177864074707, 'eval_rouge1': 10.9929, 'eval_rouge2': 4.2532, 'eval_rougeL': 9.6798, 'eval_rougeLsum': 11.0107, 'eval_runtime': 217.3446, 'eval_samples_per_second': 4.527, 'eval_steps_per_second': 1.132, 'epoch': 1.0}
 34%|███▍      | 2250/6642 [55:44<1:20:17,  1.10s/it]  {'loss': 2.5857, 'grad_norm': 2.328514337539673, 'learning_rate': 3.57538261152719e-05, 'epoch': 1.02}
 35%|███▍      | 2300/6642 [56:57<1:38:11,  1.36s/it]{'loss': 2.4735, 'grad_norm': 2.3959734439849854, 'learning_rate': 3.534679257570824e-05, 'epoch': 1.04}
 35%|███▌      | 2350/6642 [57:59<1:47:00,  1.50s/it]{'loss': 2.5136, 'grad_norm': 2.202885866165161, 'learning_rate': 3.4939759036144585e-05, 'epoch': 1.06}
 36%|███▌      | 2400/6642 [59:09<1:14:42,  1.06s/it]{'loss': 2.5112, 'grad_norm': 2.123568296432495, 'learning_rate': 3.453272549658092e-05, 'epoch': 1.08}
 36%|███▌      | 2403/6642 [59:12<1:12:46,  1.03s/it]